{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxEsGeDm0lii",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60f60d6b-630d-4e3e-cee6-477107d7a605"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting snntorch\n",
            "  Downloading snntorch-0.6.2-py2.py3-none-any.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.7/104.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from snntorch) (2.0.1+cu118)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from snntorch) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from snntorch) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from snntorch) (1.22.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.1.0->snntorch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.1.0->snntorch) (16.0.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->snntorch) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->snntorch) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.1.0->snntorch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.1.0->snntorch) (1.3.0)\n",
            "Installing collected packages: snntorch\n",
            "Successfully installed snntorch-0.6.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-3a237a213cb5>:24: DeprecationWarning: The module snntorch.backprop will be deprecated in  a future release. Writing out your own training loop will lead to substantially faster performance.\n",
            "  from snntorch import backprop\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.functional import normalize\n",
        "from PIL import Image as im\n",
        "\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "!pip install snntorch\n",
        "\n",
        "# imports\n",
        "import snntorch as snn\n",
        "from snntorch import surrogate\n",
        "from snntorch import backprop\n",
        "from snntorch import functional as SF\n",
        "from snntorch import utils\n",
        "from snntorch import spikeplot as splt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import itertools\n",
        "device = \"cpu\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngXH4N3K2gi4",
        "outputId": "c0aa542a-0a14-4b51-f7b9-12f702300212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/drive/MyDrive/ERPdata.csv')"
      ],
      "metadata": {
        "id": "5rgeXFTG3cPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meta_df=pd.read_csv('/content/drive/MyDrive/demographic.csv')"
      ],
      "metadata": {
        "id": "tv2oLNwe8EJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "_ZxDwMyzpVTN",
        "outputId": "ce0d3a0f-4e7e-4a57-a63e-db3e54348552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   subject  condition        Fz       FCz        Cz       FC3       FC4  \\\n",
              "0        1          1  5.533701  5.726507  5.469535  5.386723  4.588875   \n",
              "1        1          1  5.651489  5.837326  5.773131  5.627975  4.822217   \n",
              "2        1          1  5.717580  5.932924  5.948466  5.826460  4.979647   \n",
              "\n",
              "         C3        C4       CP3       CP4    time_ms  \n",
              "0  6.560092  4.542811  5.397492  5.103695 -1500.0000  \n",
              "1  6.739976  4.811770  5.541357  5.379273 -1499.0234  \n",
              "2  7.026199  5.053779  5.634972  5.600504 -1498.0469  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4932adef-1677-4adf-8450-78269044c381\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subject</th>\n",
              "      <th>condition</th>\n",
              "      <th>Fz</th>\n",
              "      <th>FCz</th>\n",
              "      <th>Cz</th>\n",
              "      <th>FC3</th>\n",
              "      <th>FC4</th>\n",
              "      <th>C3</th>\n",
              "      <th>C4</th>\n",
              "      <th>CP3</th>\n",
              "      <th>CP4</th>\n",
              "      <th>time_ms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5.533701</td>\n",
              "      <td>5.726507</td>\n",
              "      <td>5.469535</td>\n",
              "      <td>5.386723</td>\n",
              "      <td>4.588875</td>\n",
              "      <td>6.560092</td>\n",
              "      <td>4.542811</td>\n",
              "      <td>5.397492</td>\n",
              "      <td>5.103695</td>\n",
              "      <td>-1500.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5.651489</td>\n",
              "      <td>5.837326</td>\n",
              "      <td>5.773131</td>\n",
              "      <td>5.627975</td>\n",
              "      <td>4.822217</td>\n",
              "      <td>6.739976</td>\n",
              "      <td>4.811770</td>\n",
              "      <td>5.541357</td>\n",
              "      <td>5.379273</td>\n",
              "      <td>-1499.0234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5.717580</td>\n",
              "      <td>5.932924</td>\n",
              "      <td>5.948466</td>\n",
              "      <td>5.826460</td>\n",
              "      <td>4.979647</td>\n",
              "      <td>7.026199</td>\n",
              "      <td>5.053779</td>\n",
              "      <td>5.634972</td>\n",
              "      <td>5.600504</td>\n",
              "      <td>-1498.0469</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4932adef-1677-4adf-8450-78269044c381')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4932adef-1677-4adf-8450-78269044c381 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4932adef-1677-4adf-8450-78269044c381');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "74Grg1ks1gqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hJ58hY5weHD",
        "outputId": "489ecd70-138c-4323-9b50-68e9b2108515"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DATA PREPROCESSING\n",
        "\n",
        "a. EEG Time series data pre-processing"
      ],
      "metadata": {
        "id": "9HvdmOTgiOYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dict = {}\n",
        "data_list = []\n",
        "for i in range(1,82):\n",
        "    if i==1 or i==6 or i==16 or i==27:\n",
        "        continue\n",
        "    df_sub = df[df['subject'] == i]\n",
        "    for j in range(1,4):\n",
        "        df_subcon = df_sub[df_sub['condition'] == j]\n",
        "        df_subcon = df_subcon.drop(['subject','condition','time_ms'],axis=1)\n",
        "        record = df_subcon.to_numpy()\n",
        "        record = np.transpose(record)\n",
        "\n",
        "        record_name = str(i)+str(j)\n",
        "        data_dict[record_name] = record\n",
        "    \n",
        "        record = record.tolist()\n",
        "#         if i==2 and j==1:\n",
        "#             print(len(record))\n",
        "        dummy = []\n",
        "        dummy.append(record)\n",
        "        data_list.append(dummy)\n",
        "\n",
        "c = 0\n",
        "for key in data_dict.keys():\n",
        "    c += 1\n",
        "    #print(data_dict[key].shape)\n",
        "print(c)\n",
        "\n",
        "c = 0\n",
        "for data in data_list:\n",
        "    c += 1\n",
        "    #print(len(data))\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzkazrN1995N",
        "outputId": "90a53994-34b9-4c2a-bc63-286f27677375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "231\n",
            "231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = []\n",
        "device = \"cpu\"\n",
        "\n",
        "for i,x in enumerate(meta_df[' group'].tolist()):\n",
        "    if i==1 or i==6 or i==16 or i==27:\n",
        "        continue\n",
        "    labels.append(x)\n",
        "    labels.append(x)\n",
        "    labels.append(x)\n",
        "X = torch.Tensor(data_list).to(device)\n",
        "y = torch.Tensor(labels).to(device)\n",
        "import torch.nn.functional as F\n",
        "y = F.one_hot(y.to(torch.int64), num_classes=2)\n",
        "\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle = True)"
      ],
      "metadata": {
        "id": "mOwiAxPS-EFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y[200][0] == 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAZ5G9h7FNGG",
        "outputId": "f3b4d7b5-2cce-4a97-8249-acea1c714a8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(False)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORlIUXL8Z_Ur",
        "outputId": "26396977-b097-4cf1-c663-461c22038ef0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 9, 3072])"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for i in range(len(X)):\n",
        "    img = X[i]\n",
        "    img = np.reshape(img, (9, 3072))\n",
        "    img = (img - img.min() ) / ( img.max() - img.min()) * 255\n",
        "    # img = normalize(img, p=50)\n",
        "    # print(img.shape)\n",
        "    # print(img.min(),img.max())\n",
        "    # cv2.imwrite('test.jpg', img)\n",
        "    # cv2.imshow(\"image\", img)\n",
        "    # cv2.waitKey()\n",
        "    img = np.asarray(img)\n",
        "    data = im.fromarray(img).convert(\"L\")\n",
        "    if y[i][0] == 1:\n",
        "        data.save('/content/drive/MyDrive/ERP_imagedata/0/'+str(i)+'.jpeg')\n",
        "    else:\n",
        "        data.save('/content/drive/MyDrive/ERP_imagedata/1/'+str(i)+'.jpeg')\n"
      ],
      "metadata": {
        "id": "HQKtSCTXc2YJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img=im.open('/content/drive/MyDrive/ERP_imagedata/0/0.jpeg')\n",
        "img.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "S5aZ7JIZBRZb",
        "outputId": "4627b009-0e93-4495-8878-ffa5ce042b47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=3072x9 at 0x7F55043382E0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G-YpJdGnpQRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. Demographics data pre-processing"
      ],
      "metadata": {
        "id": "zpxFde-jpgfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Load the CSV file into a pandas dataframe\n",
        "df = pd.read_csv('/content/drive/MyDrive/demographic.csv')\n",
        "\n",
        "df = df[df['subject'] != 1]\n",
        "df = df[df['subject'] != 6]\n",
        "df = df[df['subject'] != 16]\n",
        "df = df[df['subject'] != 27]\n",
        "# print(df.head)\n",
        "\n",
        "# Preprocess the data\n",
        "# Convert categorical variable to numerical using LabelEncoder\n",
        "le = LabelEncoder()\n",
        "df[' gender'] = le.fit_transform(df[' gender'])\n",
        "\n",
        "# Scale the numerical features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "df[[' age', ' education']] = scaler.fit_transform(df[[' age', ' education']])\n",
        "\n",
        "# Separate the data into schizophrenia and non-schizophrenia groups\n",
        "df_schizophrenia = df[df[' group'] == 1]\n",
        "df_non_schizophrenia = df[df[' group'] == 0]\n",
        "\n",
        "# Create the input and output data for the ANN model\n",
        "# The input data consists of the age and education features\n",
        "# The output data consists of a binary variable indicating schizophrenia diagnosis\n",
        "X_demo = df[[' age', ' education', ' gender']].to_numpy()\n",
        "y_demo = df[' group'].to_numpy()\n",
        "\n",
        "# print(X_demo)"
      ],
      "metadata": {
        "id": "NWDWPH1ZpQUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATALOADER CREATION FOR TRAINING"
      ],
      "metadata": {
        "id": "X4VfOZi1cKvU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.imgs_path = \"/content/drive/MyDrive/ERP_imagedata/\"\n",
        "        file_list = glob.glob(self.imgs_path + \"*\")\n",
        "        print(file_list)\n",
        "        self.data = []\n",
        "        for class_path in file_list:\n",
        "            class_name = class_path.split(\"/\")[-1]\n",
        "            for img_path in glob.glob(class_path + \"/*.jpeg\"):\n",
        "                self.data.append([img_path, class_name])\n",
        "        print(self.data)\n",
        "        self.class_map = {\"0\" : 0, \"1\": 1}\n",
        "        self.img_dim = (9, 3072)    \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)    \n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        img_path, class_name = self.data[idx]\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.resize(img, self.img_dim)\n",
        "        img = TF.to_tensor(img)\n",
        "        class_id = self.class_map[class_name]\n",
        "        # img_tensor = torch.from_numpy(img)\n",
        "        img_tensor = img\n",
        "        # img_tensor = TF.to_tensor(img_tensor)\n",
        "        img_tensor = img_tensor.permute(2, 0, 1)\n",
        "        class_id = torch.tensor([class_id])\n",
        "        X_train, X_test = img_tensor[:, 0.8*len(img_tensor)], img_tensor[0.8*len(img_tensor),:]\n",
        "        y_train, y_test = class_id[:, 0.8*len(img_tensor)], class_id[0.8*len(img_tensor),:]\n",
        "        return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "AL8V8zKsJ6X1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset()\n",
        "data_loader = DataLoader(dataset, batch_size=4, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sc969dHQJ6ai",
        "outputId": "41a6bc01-db5f-4e67-ddb2-791953e07e33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/ERP_imagedata/0', '/content/drive/MyDrive/ERP_imagedata/1']\n",
            "[['/content/drive/MyDrive/ERP_imagedata/0/0.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/1.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/2.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/3.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/4.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/5.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/6.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/7.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/8.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/9.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/10.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/11.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/12.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/13.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/14.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/15.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/16.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/17.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/18.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/19.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/20.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/21.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/22.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/23.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/24.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/25.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/26.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/27.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/28.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/29.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/30.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/31.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/32.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/33.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/34.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/35.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/36.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/37.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/38.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/39.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/40.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/41.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/42.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/43.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/44.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/45.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/46.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/47.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/48.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/49.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/50.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/51.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/52.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/53.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/54.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/55.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/56.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/57.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/58.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/59.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/60.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/61.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/62.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/162.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/163.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/164.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/165.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/166.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/167.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/168.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/169.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/170.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/171.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/172.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/173.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/174.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/175.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/176.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/177.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/178.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/179.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/180.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/181.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/182.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/183.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/184.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/0/185.jpeg', '0'], ['/content/drive/MyDrive/ERP_imagedata/1/63.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/64.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/65.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/66.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/67.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/68.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/69.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/70.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/71.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/72.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/73.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/74.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/75.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/76.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/77.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/78.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/79.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/80.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/81.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/82.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/83.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/84.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/85.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/86.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/87.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/88.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/89.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/90.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/91.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/92.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/93.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/94.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/95.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/96.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/97.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/98.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/99.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/100.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/101.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/102.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/103.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/104.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/105.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/106.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/107.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/108.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/109.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/110.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/111.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/112.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/113.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/114.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/115.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/116.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/117.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/118.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/119.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/120.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/121.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/122.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/123.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/124.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/125.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/126.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/127.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/128.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/129.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/130.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/131.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/132.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/133.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/134.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/135.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/136.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/137.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/138.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/139.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/140.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/141.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/142.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/143.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/144.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/145.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/146.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/147.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/148.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/149.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/150.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/151.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/152.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/153.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/154.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/155.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/156.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/157.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/158.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/159.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/160.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/161.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/186.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/187.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/188.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/189.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/190.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/191.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/192.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/193.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/194.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/195.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/196.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/197.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/198.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/199.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/200.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/201.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/202.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/203.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/204.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/205.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/206.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/207.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/208.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/209.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/210.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/211.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/212.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/213.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/214.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/215.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/216.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/217.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/218.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/219.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/220.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/221.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/222.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/223.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/224.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/225.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/226.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/227.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/228.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/229.jpeg', '1'], ['/content/drive/MyDrive/ERP_imagedata/1/230.jpeg', '1']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "29qK0KgVMGOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NN MODEL"
      ],
      "metadata": {
        "id": "GVkhHmG-c2su"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8JEfCagrMl_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "spike_grad = surrogate.fast_sigmoid(slope=20)\n",
        "beta = 0.4\n",
        "\n",
        "lif1 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n"
      ],
      "metadata": {
        "id": "IJs3PHh3MmG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# neuron and simulation parameters\n",
        "spike_grad = surrogate.fast_sigmoid(slope=20)\n",
        "beta = 0.4\n",
        "num_steps = 50\n",
        "batch_size=4"
      ],
      "metadata": {
        "id": "17fR68PpMmKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data, targets = next(iter(data_loader))\n",
        "data = data.to(device)\n",
        "targets = targets.to(device)\n",
        "# print(data[0].shape)\n",
        "# print(data[0])\n",
        "for step in range(num_steps):\n",
        "    # data = TF.to_tensor(data)\n",
        "    spk_out, mem_out = net(data)"
      ],
      "metadata": {
        "id": "W-EaHcysNcLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_pass(net, num_steps, data):\n",
        "  mem_rec = []\n",
        "  spk_rec = []\n",
        "  utils.reset(net)  # resets hidden states for all LIF neurons in net\n",
        "\n",
        "  for step in range(num_steps):\n",
        "      spk_out, mem_out = net(data)\n",
        "      spk_rec.append(spk_out)\n",
        "      mem_rec.append(mem_out)\n",
        "  \n",
        "  return torch.stack(spk_rec), torch.stack(mem_rec)"
      ],
      "metadata": {
        "id": "QuLMezviNcNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spk_rec, mem_rec = forward_pass(net, num_steps, data)"
      ],
      "metadata": {
        "id": "yHFYUX1JNcQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# already imported snntorch.functional as SF \n",
        "loss_fn = SF.ce_rate_loss()"
      ],
      "metadata": {
        "id": "b2UMyssDNcS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets = torch.reshape(targets, (-1,))\n",
        "loss_val = loss_fn(spk_rec, targets)\n",
        "\n",
        "print(f\"The loss from an untrained network is {loss_val.item():.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfN9LoUiNcVs",
        "outputId": "9b4d409b-b6dc-4ce4-9552-be8a1454e673"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The loss from an untrained network is 0.693\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = SF.accuracy_rate(spk_rec, targets)\n",
        "\n",
        "print(f\"The accuracy of a single batch using an untrained network is {acc*100:.3f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxd_VWjKTvOD",
        "outputId": "4e194117-a658-46f4-f54a-faf253db6cc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of a single batch using an untrained network is 25.000%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_accuracy(train_loader, net, num_steps):\n",
        "  with torch.no_grad():\n",
        "    total = 0\n",
        "    acc = 0\n",
        "    net.eval()\n",
        "    \n",
        "    train_loader = iter(train_loader)\n",
        "    for data, targets in train_loader:\n",
        "      data = data.to(device)\n",
        "      targets = targets.to(device)\n",
        "      spk_rec, _ = forward_pass(net, num_steps, data)\n",
        "\n",
        "      acc += SF.accuracy_rate(spk_rec, targets) * spk_rec.size(1)\n",
        "      total += spk_rec.size(1)\n",
        "\n",
        "  return acc/total"
      ],
      "metadata": {
        "id": "1F4s0RE5MmSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(net.parameters(), lr=1e-2, betas=(0.9, 0.999))\n",
        "num_epochs = 1\n",
        "loss_hist = []\n",
        "test_acc_hist = []\n",
        "counter = 0\n",
        "\n",
        "# Outer training loop\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # Training loop\n",
        "    for data, targets in iter(data_loader):\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # forward pass\n",
        "        net.train()\n",
        "        spk_rec, _ = forward_pass(net, num_steps, data)\n",
        "        # print(targets.shape)\n",
        "        targets = torch.reshape(targets, (-1,))\n",
        "        # initialize the loss & sum over time\n",
        "        loss_val = loss_fn(spk_rec, targets)\n",
        "\n",
        "        # Gradient calculation + weight update\n",
        "        optimizer.zero_grad()\n",
        "        loss_val.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Store loss history for future plotting\n",
        "        loss_hist.append(loss_val.item())\n",
        "\n",
        "        # Test set\n",
        "        if counter % 50 == 0:\n",
        "          with torch.no_grad():\n",
        "              net.eval()\n",
        "\n",
        "              # Test set forward pass\n",
        "              test_acc = batch_accuracy(data_loader, net, num_steps)\n",
        "              print(f\"Iteration {counter}, Test Acc: {test_acc * 100:.2f}%\\n\")\n",
        "              test_acc_hist.append(test_acc.item())\n",
        "\n",
        "        counter += 1"
      ],
      "metadata": {
        "id": "l0prach2T0P9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Loss\n",
        "fig = plt.figure(facecolor=\"w\")\n",
        "plt.plot(test_acc_hist)\n",
        "plt.title(\"Test Set Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lFCm9D3dT0St"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AgOSmqy9T0WM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0XNOHsNFT0ZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class NetNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        beta = 0.5  # neuron decay rate\n",
        "        spike_grad = surrogate.fast_sigmoid() # surrogate gradient\n",
        "        self.conv1 = nn.Conv2d(1, 2, (9,48))\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(2, 1, 1)\n",
        "        self.fc1 = nn.Linear(3025, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        # print(x.shape)\n",
        "        x = self.conv2(x)\n",
        "        # print(x.shape)\n",
        "        x = F.relu(x)\n",
        "        # print(x.shape)\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        # print(x.shape)\n",
        "        x = self.fc1(x)\n",
        "        # print(x.shape)\n",
        "        x = F.relu(x)\n",
        "        # print(x.shape)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        # print(x.shape)\n",
        "        x = self.fc3(x)\n",
        "        # x = self.spike_out(x)\n",
        "        # print(x.shape)\n",
        "        return x\n",
        "\n",
        "net = NetNN()\n",
        "net"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSI-NXzD-EJM",
        "outputId": "3a2afdf8-36df-400b-e2a6-642f9354b637"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NetNN(\n",
              "  (conv1): Conv2d(1, 2, kernel_size=(9, 48), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=3025, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
              "  (fc3): Linear(in_features=32, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(data_x, data_y, X_test, y_test, learning_rate, n_epochs):\n",
        "\n",
        "    device = \"cpu\"\n",
        "    print(f\"Using {device} device\")\n",
        "    model = NetNN().to(device)\n",
        "    print(\"MODEL:\", model)\n",
        "\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.NAdam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    losses = []\n",
        "    for epoch in range(n_epochs):\n",
        "        correct, accuracy = 0, 0\n",
        "        pred_y = model(data_x)\n",
        "        print(type(pred_y), type(data_y))\n",
        "        loss = loss_function(pred_y, data_y)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # _, predicted = torch.max(pred_y.data, 1)\n",
        "        # print(pred_y.argmax(dim=1), data_y.argmax(dim=1))\n",
        "        # print(pred_y, data_y)\n",
        "        correct += (pred_y.argmax(dim=1) == data_y.argmax(dim=1)).float().sum()\n",
        "\n",
        "        print(\"\\nEpoch:\", epoch)\n",
        "        accuracy = 100 * correct / len(data_y)\n",
        "        print(\"Train:\")\n",
        "        print(\"Accuracy = {}\".format(accuracy))\n",
        "        print(\"Loss = \", loss.item())\n",
        "\n",
        "        test(model, X_test, y_test)\n",
        "\n",
        "        if accuracy>95:\n",
        "            break\n",
        "        if epoch%10 == 0:\n",
        "            learning_rate = learning_rate/0.01\n",
        "            optimizer.param_groups[0]['lr'] = learning_rate\n",
        "\n",
        "    return model, losses\n",
        "\n",
        "def test(model, X_test, y_test):\n",
        "    pred_y = model(X_test)\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "    print(type(pred_y), type(y_test))\n",
        "    loss = loss_function(pred_y, y_test)\n",
        "\n",
        "    correct = (pred_y.argmax(dim=1) == y_test.argmax(dim=1)).float().sum()\n",
        "\n",
        "    accuracy = 100 * correct / len(X_test)\n",
        "    print(\"Test:\")\n",
        "    print(\"Accuracy = {}\".format(accuracy))\n",
        "    print(\"Loss = \", loss.item())"
      ],
      "metadata": {
        "id": "PrFzb9eRczeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, X_test, y_test):\n",
        "    pred_y = model(X_test)\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "    print(type(pred_y), type(y_test))\n",
        "    loss = loss_function(pred_y, y_test)\n",
        "\n",
        "    correct = (pred_y.argmax(dim=1) == y_test.argmax(dim=1)).float().sum()\n",
        "\n",
        "    accuracy = 100 * correct / len(X_test)\n",
        "    print(\"Accuracy = {}\".format(accuracy))\n",
        "    print(\"Loss = \", loss.item())\n"
      ],
      "metadata": {
        "id": "CpCEMebuczjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(modelNN_1, X_test, y_test.float())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lefDLTjhBVm",
        "outputId": "c2186df0-8c02-4686-a34a-af9376fea56e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "Accuracy = 55.319149017333984\n",
            "Loss =  2.657017469406128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i3t5sKFbhBYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SNN MODEL"
      ],
      "metadata": {
        "id": "qats8bkXcz29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        beta = 0.5  # neuron decay rate\n",
        "        spike_grad = surrogate.fast_sigmoid() # surrogate gradient\n",
        "        self.conv1 = nn.Conv2d(1, 2, (9,1536))\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(2, 1, 1)\n",
        "        self.fc1 = nn.Linear(3074, 1537)\n",
        "        self.fc2 = nn.Linear(1537, 1537)\n",
        "        self.fc3 = nn.Linear(1537, 2)\n",
        "        self.spike = snn.Leaky(beta=beta, init_hidden=True, spike_grad=spike_grad)\n",
        "        self.spike_out = snn.Leaky(beta=beta, init_hidden=True, spike_grad=spike_grad, output=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.spike(x)\n",
        "        print(x.shape)\n",
        "        x = self.conv2(x)\n",
        "        print(x.shape)\n",
        "        x = self.spike(x)\n",
        "        print(x.shape)\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = self.fc1(x)\n",
        "        print(x.shape)\n",
        "        x = self.spike(x)\n",
        "        print(x.shape)\n",
        "        x = self.fc2(x)\n",
        "        x = self.spike(x)\n",
        "        print(x.shape)\n",
        "        x = self.fc3(x)\n",
        "        # x = self.spike_out(x)\n",
        "        print(x.shape)\n",
        "        return x\n",
        "\n",
        "net = Net()\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n"
      ],
      "metadata": {
        "id": "1krfa0i98Z-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(data_x, data_y, learning_rate, n_epochs):\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"Using {device} device\")\n",
        "    model = Net().to(device)\n",
        "    print(\"MODEL:\", model)\n",
        "\n",
        "    loss_function = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    losses = []\n",
        "    for epoch in range(n_epochs):\n",
        "        correct, accuracy = 0, 0\n",
        "        pred_y = model(data_x)\n",
        "        print(type(pred_y), type(data_y))\n",
        "        loss = loss_function(pred_y, data_y)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # _, predicted = torch.max(pred_y.data, 1)\n",
        "        # print(pred_y.argmax(dim=1), data_y.argmax(dim=1))\n",
        "        print(pred_y, data_y)\n",
        "        correct += (pred_y.argmax(dim=1) == data_y.argmax(dim=1)).float().sum()\n",
        "\n",
        "        print(\"\\nEpoch:\", epoch)\n",
        "        accuracy = 100 * correct / len(data_y)\n",
        "        print(\"Accuracy = {}\".format(accuracy))\n",
        "        print(\"Loss = \", loss.item())\n",
        "\n",
        "        if epoch%10 == 0:\n",
        "            learning_rate = learning_rate/0.01\n",
        "\n",
        "    return model, losses"
      ],
      "metadata": {
        "id": "uMYoJV3b8d4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1, losses1 = train(X_train, y_train.float(), 0.01, 200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RVhGqu29-WyJ",
        "outputId": "8ab79251-fbe8-4890-d8bc-d1f112083fa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "MODEL: Net(\n",
            "  (conv1): Conv2d(1, 2, kernel_size=(9, 1536), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=3074, out_features=1537, bias=True)\n",
            "  (fc2): Linear(in_features=1537, out_features=1537, bias=True)\n",
            "  (fc3): Linear(in_features=1537, out_features=2, bias=True)\n",
            "  (spike): Leaky()\n",
            "  (spike_out): Leaky()\n",
            ")\n",
            "torch.Size([184, 2, 1, 1537])\n",
            "torch.Size([184, 1, 1, 1537])\n",
            "torch.Size([184, 2, 1, 1537])\n",
            "torch.Size([184, 1537])\n",
            "torch.Size([184, 2, 184, 1537])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-876abfce592e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-35-72d8b751f9b1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data_x, data_y, learning_rate, n_epochs)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mpred_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-83661daf9e49>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/snntorch/_neurons/leaky.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_, mem)\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_leaky_forward_cases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmem_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_state_function_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_quant\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/snntorch/_neurons/leaky.py\u001b[0m in \u001b[0;36m_build_state_function_hidden\u001b[0;34m(self, input_)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_mechanism_val\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# reset by subtraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             state_fn = (\n\u001b[0;32m--> 226\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_state_function_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m                 \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             )\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 398.00 MiB (GPU 0; 14.75 GiB total capacity; 13.28 GiB already allocated; 306.81 MiB free; 13.37 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "python3.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "b0Tp5APE-YfI",
        "outputId": "bd9c77c7-0e91-4504-dbf4-09b2ef2b0ca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-cd8ef756a1b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpython3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'python3' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-bqLHizeBVQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B7FNMoETr5_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QMzmw1-Ir6Dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ERP+DEMOGRAPHICS"
      ],
      "metadata": {
        "id": "zrZ5tynlr6Sr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2TmHYJAOr8YW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class NetNN_comb(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        beta = 0.5  # neuron decay rate\n",
        "        spike_grad = surrogate.fast_sigmoid() # surrogate gradient\n",
        "        self.conv1 = nn.Conv2d(1, 2, (9,48))\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(2, 1, 1)\n",
        "        self.fc1 = nn.Linear(3025, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 2)\n",
        "        self.fc1_d = nn.Linear(3,3) \n",
        "        self.fc2_d = nn.Linear(3,3)\n",
        "        self.fc3_D = nn.Linear(3,2)\n",
        "\n",
        "    def forward(self, x, d):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "\n",
        "        d = F.relu(self.fc1_d(d))\n",
        "        d = F.relu(self.fc2_d(d))\n",
        "\n",
        "        x = torch.cat((x,d),1)\n",
        "        \n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "net = NetNN_comb()\n",
        "net"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJiMy6a1r_6l",
        "outputId": "c6a2a85d-5c92-430f-ae13-520bd3d8edf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NetNN_comb(\n",
              "  (conv1): Conv2d(1, 2, kernel_size=(9, 48), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=3025, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
              "  (fc3): Linear(in_features=32, out_features=2, bias=True)\n",
              "  (fc1_d): Linear(in_features=3, out_features=3, bias=True)\n",
              "  (fc2_d): Linear(in_features=3, out_features=3, bias=True)\n",
              "  (fc3_D): Linear(in_features=3, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        beta = 0.5  # neuron decay rate\n",
        "        spike_grad = surrogate.fast_sigmoid() # surrogate gradient\n",
        "        self.conv1 = nn.Conv2d(1, 2, (9,1536))\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(2, 1, 1)\n",
        "        self.fc1 = nn.Linear(3074, 1537)\n",
        "        self.fc2 = nn.Linear(1537, 1537)\n",
        "        self.fc3 = nn.Linear(1537, 2)\n",
        "        self.fc1_d = nn.Linear(3,3) \n",
        "        self.fc2_d = nn.Linear(3,3)\n",
        "        self.spike = snn.Leaky(beta=beta, init_hidden=True, spike_grad=spike_grad)\n",
        "        self.spike_out = snn.Leaky(beta=beta, init_hidden=True, spike_grad=spike_grad, output=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.spike(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.spike(x)\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        d = F.relu(self.fc1_d(d))\n",
        "        d = F.relu(self.fc2_d(d))\n",
        "        x = torch.cat((x,d),1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.spike(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.spike(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.spike_out(x)\n",
        "        return x\n",
        "\n",
        "net = Net()\n"
      ],
      "metadata": {
        "id": "Wov_6OVtuBpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZTXwQnz7GhK",
        "outputId": "006d37b6-96d4-408e-cf26-3bef3cbf54e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(1, 2, kernel_size=(9, 1536), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=3074, out_features=1537, bias=True)\n",
              "  (fc2): Linear(in_features=1537, out_features=1537, bias=True)\n",
              "  (fc3): Linear(in_features=1537, out_features=2, bias=True)\n",
              "  (fc1_d): Linear(in_features=3, out_features=3, bias=True)\n",
              "  (fc2_d): Linear(in_features=3, out_features=3, bias=True)\n",
              "  (spike): Leaky()\n",
              "  (spike_out): Leaky()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(data_x, data_demo, data_y, X_test, y_test, learning_rate, n_epochs):\n",
        "\n",
        "    device = \"cpu\"\n",
        "    print(f\"Using {device} device\")\n",
        "    model = NetNN().to(device)\n",
        "    print(\"MODEL:\", model)\n",
        "\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.NAdam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    losses = []\n",
        "    for epoch in range(n_epochs):\n",
        "        correct, accuracy = 0, 0\n",
        "        pred_y = model(data_x, data_demo)\n",
        "        print(type(pred_y), type(data_y))\n",
        "        loss = loss_function(pred_y, data_y)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # _, predicted = torch.max(pred_y.data, 1)\n",
        "        # print(pred_y.argmax(dim=1), data_y.argmax(dim=1))\n",
        "        # print(pred_y, data_y)\n",
        "        correct += (pred_y.argmax(dim=1) == data_y.argmax(dim=1)).float().sum()\n",
        "\n",
        "        print(\"\\nEpoch:\", epoch)\n",
        "        accuracy = 100 * correct / len(data_y)\n",
        "        print(\"Train:\")\n",
        "        print(\"Accuracy = {}\".format(accuracy))\n",
        "        print(\"Loss = \", loss.item())\n",
        "\n",
        "        test(model, X_test, y_test)\n",
        "\n",
        "        if accuracy>95:\n",
        "            break\n",
        "        if epoch%10 == 0:\n",
        "            learning_rate = learning_rate/0.01\n",
        "            optimizer.param_groups[0]['lr'] = learning_rate\n",
        "\n",
        "    return model, losses\n",
        "\n",
        "def test(model, X_test, y_test):\n",
        "    pred_y = model(X_test)\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "    print(type(pred_y), type(y_test))\n",
        "    loss = loss_function(pred_y, y_test)\n",
        "\n",
        "    correct = (pred_y.argmax(dim=1) == y_test.argmax(dim=1)).float().sum()\n",
        "\n",
        "    accuracy = 100 * correct / len(X_test)\n",
        "    print(\"Test:\")\n",
        "    print(\"Accuracy = {}\".format(accuracy))\n",
        "    print(\"Loss = \", loss.item())"
      ],
      "metadata": {
        "id": "ATZqz4eG8T3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelNN_1, lossesNN_1 = train(X_train, y_train.float(), X_test, y_test.float(), 0.001, 200)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvaGHc-sCPUj",
        "outputId": "d2fc621a-6c2e-41b7-a26f-c48138e40d79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n",
            "Train:\n",
            "Accuracy = 76.08695983886719\n",
            "Loss =  0.4417681396007538\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "Test:\n",
            "Accuracy = 68.0851058959961\n",
            "Loss =  0.0615653944015503\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "\n",
            "Epoch: 1\n",
            "Train:\n",
            "Accuracy = 78.43478393554688\n",
            "Loss =  0.43978118896484375\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "Test:\n",
            "Accuracy = 70.2127685546875\n",
            "Loss =  0.0760687098503113\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "\n",
            "Epoch: 2\n",
            "Train:\n",
            "Accuracy = 77.82608795166016\n",
            "Loss =  0.2674464464187622\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "Test:\n",
            "Accuracy = 71.446807861328125\n",
            "Loss =  0.0758897476196289\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "\n",
            "Epoch: 3\n",
            "Train:\n",
            "Accuracy = 79.34782409667969\n",
            "Loss =  0.0499589717388153\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "Test:\n",
            "Accuracy = 73.82978820800781\n",
            "Loss =  0.0905491137504578\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "\n",
            "Epoch: 4\n",
            "Train:\n",
            "Accuracy = 69.02173614501953\n",
            "Loss =  0.09313334703445435\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "Test:\n",
            "Accuracy = 68.0851058959961\n",
            "Loss =  0.0825000047683716\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "\n",
            "Epoch: 5\n",
            "Train:\n",
            "Accuracy = 79.89130401611328\n",
            "Loss =  0.04515164613723755\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "Test:\n",
            "Accuracy = 74.46808624267578\n",
            "Loss =  0.0630729746818542\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "\n",
            "Epoch: 6\n",
            "Train:\n",
            "Accuracy = 79.34782409667969\n",
            "Loss =  0.04311726927757263\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "Test:\n",
            "Accuracy = 75.2127685546875\n",
            "Loss =  0.0756471109390259\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "\n",
            "Epoch: 7\n",
            "Train:\n",
            "Accuracy = 80.97826385498047\n",
            "Loss =  0.03861737909317017\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "Test:\n",
            "Accuracy = 76.46808624267578\n",
            "Loss =  0.0756721258163452\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "\n",
            "Epoch: 8\n",
            "Train:\n",
            "Accuracy = 82.06521606445312\n",
            "Loss =  0.03282437086105347\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "Test:\n",
            "Accuracy = 80.2127685546875\n",
            "Loss =  0.0740962195396423\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "\n",
            "Epoch: 9\n",
            "Train:\n",
            "Accuracy = 82.60869598388672\n",
            "Loss =  0.0361334433555603\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "Test:\n",
            "Accuracy = 80.46808624267578\n",
            "Loss =  0.0643580436706543\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "\n",
            "Epoch: 10\n",
            "Train:\n",
            "Accuracy = 82.60869598388672\n",
            "Loss =  0.03515155577659607\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "Test:\n",
            "Accuracy = 80.2127685546875\n",
            "Loss =  0.0710130715370178\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "\n",
            "Epoch: 11\n",
            "Train:\n",
            "Accuracy = 83.6363639831543\n",
            "Loss =  0.03235085308551788\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "Test:\n",
            "Accuracy = 84.0\n",
            "Loss =  0.06263586282730102\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "\n",
            "Epoch: 12\n",
            "Train:\n",
            "Accuracy = 82.60869598388672\n",
            "Loss =  0.0367285430431366\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "Test:\n",
            "Accuracy = 81.70212936401367\n",
            "Loss =  0.8409569263458252\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "\n",
            "Epoch: 13\n",
            "Train:\n",
            "Accuracy = 86.41304016113281\n",
            "Loss =  0.03578157210350037\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "Test:\n",
            "Accuracy = 75.82978820800781\n",
            "Loss =  0.1541926622390747\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(modelNN_1.state_dict(), 'erp_training_model')"
      ],
      "metadata": {
        "id": "VO4tTRmcCnG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual = y_test\n",
        "actual"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2F7E7dGLIfdb",
        "outputId": "d01c948d-efb3-4b84-ee76-2ef707330ed9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
              "       1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
              "       1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
              "       0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n",
              "       1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = modelNN_1.predict(X_test)\n",
        "predicted"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8_FfVr0IfgN",
        "outputId": "b416ab7f-a57e-4aa1-c2e3-2fc812fd3698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
              "       0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
              "       1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
              "       0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "from sklearn import metrics\n",
        "\n",
        "confusion_matrix = metrics.confusion_matrix(actual, predicted)\n",
        "\n",
        "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
        "\n",
        "cm_display.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "BnD-dWWzIfia",
        "outputId": "62c396e9-fb86-4290-a67a-decb55f46230"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qplokTHMIflk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7E-sCjrlIfod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iIHR37SbIfq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CcF_amq0IfuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H0IEThZ9IfxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-8V6g79pIf0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L7pYKreCIf2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kFOXh3tRIf6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Epoch: 0\n",
        "Train:\n",
        "Accuracy = 76.08695983886719\n",
        "Loss =  0.4417681396007538\n",
        "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
        "Test:\n",
        "Accuracy = 68.0851058959961\n",
        "Loss =  0.0615653944015503\n",
        "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
        "\n",
        "Epoch: 1\n",
        "Train:\n",
        "Accuracy = 78.43478393554688\n",
        "Loss =  0.43978118896484375\n",
        "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
        "Test:\n",
        "Accuracy = 70.2127685546875\n",
        "Loss =  0.0760687098503113\n",
        "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
        "\n",
        "Epoch: 2\n",
        "Train:\n",
        "Accuracy = 77.82608795166016\n",
        "Loss =  0.2674464464187622\n",
        "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
        "Test:\n",
        "Accuracy = 71.446807861328125\n",
        "Loss =  0.0758897476196289\n",
        "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
        "\n",
        "Epoch: 3\n",
        "Train:\n",
        "Accuracy = 79.34782409667969\n",
        "Loss =  0.0499589717388153\n",
        "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
        "Test:\n",
        "Accuracy = 73.82978820800781\n",
        "Loss =  0.0905491137504578\n",
        "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
        "\n",
        "Epoch: 4\n",
        "Train:\n",
        "Accuracy = 69.02173614501953\n",
        "Loss =  0.09313334703445435\n",
        "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
        "Test:\n",
        "Accuracy = 68.0851058959961\n",
        "Loss =  0.0825000047683716\n",
        "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
        "\n",
        "Epoch: 5\n",
        "Train:\n",
        "Accuracy = 79.89130401611328\n",
        "Loss =  0.04515164613723755\n",
        "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
        "Test:\n",
        "Accuracy = 74.46808624267578\n",
        "Loss =  0.0630729746818542\n",
        "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
        "\n",
        "Epoch: 6\n",
        "Train:\n",
        "Accuracy = 79.34782409667969\n",
        "Loss =  0.04311726927757263\n",
        "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
        "Test:\n",
        "Accuracy = 75.2127685546875\n",
        "Loss =  0.0756471109390259\n",
        "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
        "\n",
        "Epoch: 7\n",
        "Train:\n",
        "Accuracy = 80.97826385498047\n",
        "Loss =  0.03861737909317017\n",
        "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
        "Test:\n",
        "Accuracy = 76.46808624267578\n",
        "Loss =  0.0756721258163452\n",
        "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
        "\n",
        "Epoch: 8\n",
        "Train:\n",
        "Accuracy = 82.06521606445312\n",
        "Loss =  0.03282437086105347\n",
        "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
        "Test:\n",
        "Accuracy = 80.2127685546875\n",
        "Loss =  0.0740962195396423\n",
        "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
        "\n",
        "Epoch: 9\n",
        "Train:\n",
        "Accuracy = 82.60869598388672\n",
        "Loss =  0.0361334433555603\n",
        "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
        "Test:\n",
        "Accuracy = 80.46808624267578\n",
        "Loss =  0.0643580436706543\n",
        "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
        "\n",
        "Epoch: 10\n",
        "Train:\n",
        "Accuracy = 82.60869598388672\n",
        "Loss =  0.03515155577659607\n",
        "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
        "Test:\n",
        "Accuracy = 80.2127685546875\n",
        "Loss =  0.0710130715370178\n",
        "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
        "\n",
        "Epoch: 11\n",
        "Train:\n",
        "Accuracy = 83.6363639831543\n",
        "Loss =  0.03235085308551788\n",
        "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
        "Test:\n",
        "Accuracy = 84.0\n",
        "Loss =  0.06263586282730102\n",
        "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
        "\n",
        "Epoch: 12\n",
        "Train:\n",
        "Accuracy = 82.60869598388672\n",
        "Loss =  0.0367285430431366\n",
        "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
        "Test:\n",
        "Accuracy = 81.70212936401367\n",
        "Loss =  0.8409569263458252\n",
        "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
        "\n",
        "Epoch: 13\n",
        "Train:\n",
        "Accuracy = 86.41304016113281\n",
        "Loss =  0.03578157210350037\n",
        "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
        "Test:\n",
        "Accuracy = 75.82978820800781\n",
        "Loss =  0.1541926622390747\n",
        "<class 'torch.Tensor'> <class 'torch.Tensor'>"
      ],
      "metadata": {
        "id": "KQSMuUyTIf9N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}